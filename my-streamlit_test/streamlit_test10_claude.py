# å¯¾è©±å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³
# ææ¡ˆã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã®å¤‰æ›´ã€€ï¼‘ï¼modelã‚’gpt-4oã‹ã‚‰gpt-5-miniã«å¤‰æ›´ã€ï¼’ï¼ŒAIå›ç­”ã®æ–‡é ­ã‹ã‚‰ä¾é ¼åˆ†ã‚’å‰Šé™¤
import streamlit as st
import asyncio
from autogen_agentchat.agents import AssistantAgent
#from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_ext.models.anthropic import AnthropicChatCompletionClient
from autogen_agentchat.messages import TextMessage
import os
from dotenv import load_dotenv
load_dotenv()

#config_list = [
#    {
#        "model": "claude-sonnet-4-20250514",
#        "api_key": os.getenv("ANTHROPIC_API_KEY"),
#        "api_type": "anthropic"
#    }
#]

st.set_page_config(page_title="AutoGen x Streamlit App", layout="centered")
st.title("ğŸ¤– AutoGen å¯¾è©±å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")

# --- 1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰ ---
@st.cache_resource

def get_model_client():
    # ç’°å¢ƒå¤‰æ•° ANTHROPIC_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å‰æ
    return AnthropicChatCompletionClient(
    #    model="claude-sonnet-4-20250514", # ä»»æ„ã®ãƒ¢ãƒ‡ãƒ«
        model="claude-sonnet-4-5-20250929",
    #    model="claude-haiku-4-5-20251001",
        temperature=0.7,
    )

def get_agent():
    if "agent" not in st.session_state:
        client = get_model_client()
        st.session_state.agent = AssistantAgent(
            name="assistant",
            model_client=client, # ã“ã“ã«Claudeç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æ¸¡ã™
            system_message="ã‚ãªãŸã¯æœ‰èƒ½ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„å›ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"
        )
    return st.session_state.agent

#def get_agent():
    # ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šæ¸ˆã¿ã§ã‚ã‚‹å‰æ
    # model_client = OpenAIChatCompletionClient(model="gpt-5-mini")
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆï¼ˆã“ã“ã§MCPãƒ„ãƒ¼ãƒ«ãªã©ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ï¼‰

#    agent = AssistantAgent(
#        name="assistant",
#        llm_config={
#            "config_list": config_list,
#            "temperature": 0.7,
#        },
#        model_client=model_client,
#        system_message="ã‚ãªãŸã¯æœ‰èƒ½ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„å›ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"
#    )
#    return agent

agent = get_agent()

# --- 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼ˆä¼šè©±å±¥æ­´ã®ä¿å­˜ç”¨ï¼‰ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 3. ä¿å­˜ã•ã‚ŒãŸå±¥æ­´ã®è¡¨ç¤º ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- 4. ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆéåŒæœŸé–¢æ•°ã¨ã—ã¦å®šç¾©ï¼‰ ---
async def run_chat(prompt):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ç”»é¢ã«è¡¨ç¤º & å±¥æ­´ã«è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”é ˜åŸŸã‚’ä½œæˆ
    with st.chat_message("assistant"):
        container = st.empty()  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºç”¨ã®ç©ºæ 
        full_response = ""
        
        # run_stream ã‚’ä½¿ç”¨ã—ã¦é€æ¬¡å–å¾—
        # â€» å®Ÿéš›ã®å®Ÿè£…ã§ã¯ TaskResult ãŒæµã‚Œã¦ãã‚‹ãŸã‚ã€ãã‚Œã‚’å–ã‚Šå‡ºã™
        async for chunk in agent.run_stream(task=prompt):
            # chunkã®ç¨®é¡ï¼ˆæ€è€ƒä¸­ã€ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œä¸­ã€æœ€çµ‚å›ç­”ãªã©ï¼‰ã‚’åˆ¤å®š
            # ä¸‹è¨˜ã¯ç°¡æ˜“çš„ã«ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸
            # if hasattr(chunk, 'content') and chunk.content:
            # ä¸Šã®ã‚³ãƒ¼ãƒ‰ã‚’å¤‰æ›´ï¼ˆæ–‡é ­ã®å…¥åŠ›æ–‡ã‚’å‰Šé™¤ï¼‰ã€€2026å¹´æœ€æ–°ä»•æ§˜ã®åˆ¤å®šæ–¹æ³•ï¼š
            # chunkãŒã€ŒTextMessageã€ã§ã‚ã‚Šã€ã‹ã¤é€ä¿¡å…ƒãŒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªèº«ï¼ˆagent.nameï¼‰ã§ã‚ã‚‹å ´åˆã®ã¿æ¡ç”¨ã™ã‚‹
            # ã“ã‚Œã«ã‚ˆã‚Šã€å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆuserã‹ã‚‰ã®ãƒ­ã‚°ï¼‰ãŒæ··ã–ã‚‹ã®ã‚’é˜²ãã¾ã™
            if isinstance(chunk, TextMessage) and chunk.source == agent.name:
                full_response += chunk.content
                container.markdown(full_response + "â–Œ") # ã‚«ãƒ¼ã‚½ãƒ«é¢¨ã®æ¼”å‡º
        
        container.markdown(full_response) # æœ€çµ‚çµæœã‚’ç¢ºå®šè¡¨ç¤º
        st.session_state.messages.append({"role": "assistant", "content": full_response})

# --- 5. å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  ---
if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # Streamlitã®åŒæœŸå‡¦ç†ã®ä¸­ã§éåŒæœŸé–¢æ•°ã‚’å®Ÿè¡Œã™ã‚‹
    asyncio.run(run_chat(prompt))

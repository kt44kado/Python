# Notion å¯¾è©±å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€€ã‚¨ãƒ©ãƒ¼å¯¾å¿œãƒãƒ¼ã‚¸ãƒ§ãƒ³ 

import os
import json
import threading

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

import streamlit as st
import asyncio

from autogen_core import CancellationToken
from autogen_core.tools import FunctionTool

from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_agentchat.messages import TextMessage
from autogen_agentchat.agents import AssistantAgent


class McpNotionClient:
    def __init__(self, notion_api_key: str):
        self.notion_api_key = notion_api_key
        self._thread = None
        self._loop = None
        self._ready = threading.Event()
        self._shutdown = None
        self._session = None
        self.tools = []

        self.server_params = StdioServerParameters(
            command="npx",
            args=["-y", "@notionhq/notion-mcp-server"],
            env={**os.environ, 
                 "NOTION_API_KEY": self.notion_api_key
                },
        )

    def start(self):
        self._thread = threading.Thread(target=self._thread_main, daemon=True)
        self._thread.start()
        self._ready.wait(timeout=60)
        if not self._ready.is_set():
            raise RuntimeError("MCP Notion client failed to become ready in time.")

    def close(self):
        if not self._loop:
            return
        asyncio.run_coroutine_threadsafe(self._async_shutdown(), self._loop).result(timeout=30)
        self._loop.call_soon_threadsafe(self._loop.stop)
        if self._thread:
            self._thread.join(timeout=30)

    def call_tool(self, tool_name: str, arguments: dict):
        if not self._ready.is_set():
            raise RuntimeError("MCP Notion client is not ready yet.")
        coro = self._session.call_tool(name=tool_name, arguments=arguments)
        fut = asyncio.run_coroutine_threadsafe(coro, self._loop)
        return fut.result(timeout=60)

    def _thread_main(self):
        self._loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self._loop)
        self._loop.create_task(self._runner())
        self._loop.run_forever()

    async def _runner(self):
        self._shutdown = asyncio.Event()
        async with stdio_client(self.server_params) as (read, write):
            async with ClientSession(read, write) as session:
                await session.initialize()
                self._session = session
                resp = await session.list_tools()
                self.tools = resp.tools
                self._ready.set()
                await self._shutdown.wait()

    async def _async_shutdown(self):
        if self._shutdown:
            self._shutdown.set()


def format_tools_for_prompt(mcp_tools) -> str:
    lines = []
    for t in mcp_tools:
        lines.append(
            f"- name: {t.name}\n"
            f"  description: {t.description}\n"
            f"  inputSchema: {json.dumps(t.inputSchema, ensure_ascii=False)}\n"
        )
    return "\n".join(lines)


st.set_page_config(page_title="AutoGen x Streamlit App", layout="centered")
st.title("ğŸ¤– AutoGen å¯¾è©±å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")

# --- 1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰ ---
@st.cache_resource
def get_mcp_client():
    notion_token = st.secrets["NOTION_TOKEN"] # Streamlitã§ã¯Secretsç®¡ç†ã‚’æ¨å¥¨
    client = McpNotionClient(notion_api_key=notion_token)
    client.start()  # æ¥ç¶šé–‹å§‹
    return client

# --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾è±¡2: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãƒ„ãƒ¼ãƒ«ã®æ§‹ç¯‰ ---
@st.cache_resource
def get_assistant():
    mcp_client = get_mcp_client() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
    # ãƒ„ãƒ¼ãƒ«ã‚«ã‚¿ãƒ­ã‚°ã®ä½œæˆ
    tools_catalog = format_tools_for_prompt(mcp_client.tools)
    system_message = f"""You are an assistant that manipulates Notion via Notion MCP tools.

### IMPORTANT RULE:
1. You MUST call the tool `mcp_call_tool(tool_name, arguments)` to execute actions.
2. You MUST use the EXACT `tool_name` found in the 'MCP tool catalog' below.
   DO NOT add prefixes/suffixes and DO NOT guess the tool name.
3. If a tool call fails with 'Method not found', re-check the catalog and use the correct name.
4. Choose tool_name from the catalog and pass arguments matching inputSchema.

### MCP tool catalog:
{tools_catalog}
"""
    
    model_client = OpenAIChatCompletionClient(model="gpt-5-mini")

    # ãƒ„ãƒ¼ãƒ«é–¢æ•°å®šç¾©
    def mcp_call_tool(tool_name: str, arguments: dict) -> dict:
        result = mcp_client.call_tool(tool_name, arguments)
        # JSONå¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯...
        return result

    mcp_tool = FunctionTool(
        mcp_call_tool,
        name="mcp_call_tool",
        description="Notionã‚’æ“ä½œã™ã‚‹ãŸã‚ã«ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚'tool_name'ã«ã¯å®Ÿè¡Œã—ãŸã„APIåã‚’ã€'arguments'ã«ã¯ãã®APIã«å¿…è¦ãªå¼•æ•°ã‚’è¾æ›¸å½¢å¼ã§æ¸¡ã—ã¦ãã ã•ã„ã€‚ä¾‹: mcp_call_tool(tool_name='API-post-page', arguments={'parent': {...}, 'properties': {...}})",
    )

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    assistant = AssistantAgent(
        name="assistant",
        system_message=system_message,
        model_client=model_client,
        tools=[mcp_tool],
    )
    return assistant


def print_mcp_tools_list(mcp_tools):
    """
    MCPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰å–å¾—ã—ãŸãƒ„ãƒ¼ãƒ«ã®ä¸€è¦§ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤ºã™ã‚‹
    """
    print("\n" + "="*50)
    print(f"ã€Notion MCP æ“ä½œãƒ„ãƒ¼ãƒ«ä¸€è¦§è¡¨ã€‘ åˆè¨ˆ: {len(mcp_tools)}å€‹")
    print("="*50)

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
# --- 1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰ ---
assistant = get_assistant()

# --- 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼ˆä¼šè©±å±¥æ­´ã®ä¿å­˜ç”¨ï¼‰ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 3. ä¿å­˜ã•ã‚ŒãŸå±¥æ­´ã®è¡¨ç¤º ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- 4. ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆéåŒæœŸé–¢æ•°ã¨ã—ã¦å®šç¾©ï¼‰ ---
async def run_chat(prompt):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ç”»é¢ã«è¡¨ç¤º & å±¥æ­´ã«è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”é ˜åŸŸã‚’ä½œæˆ
    with st.chat_message("assistant"):
        container = st.empty()  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºç”¨ã®ç©ºæ 
        full_response = ""
        
        # run_stream ã‚’ä½¿ç”¨ã—ã¦é€æ¬¡å–å¾—
        # â€» å®Ÿéš›ã®å®Ÿè£…ã§ã¯ TaskResult ãŒæµã‚Œã¦ãã‚‹ãŸã‚ã€ãã‚Œã‚’å–ã‚Šå‡ºã™
        async for chunk in assistant.run_stream(task=prompt):
            # 1. é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå›ç­”ã®å‡¦ç†
            if isinstance(chunk, TextMessage) and chunk.source == assistant.name:
                full_response += chunk.content
                container.markdown(full_response + "â–Œ") # ã‚«ãƒ¼ã‚½ãƒ«é¢¨ã®æ¼”å‡º
            
            # 2. ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã®å‡¦ç†ã‚’è¿½åŠ 
            elif hasattr(chunk, 'is_error') and chunk.is_error:
                error_msg = f"\n\nâš ï¸ **ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼:** {chunk.content}"
                full_response += error_msg
                container.markdown(full_response)
        
        # æœ€çµ‚çµæœã®è¡¨ç¤ºï¼ˆä½•ã‚‚è¿”ã£ã¦ã“ãªã‹ã£ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        if not full_response:
            full_response = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã«å¤±æ•—ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰ã€‚"
        
        container.markdown(full_response) # æœ€çµ‚çµæœã‚’ç¢ºå®šè¡¨ç¤º
        st.session_state.messages.append({"role": "assistant", "content": full_response})

# --- 5. å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  ---
if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # Streamlitã®åŒæœŸå‡¦ç†ã®ä¸­ã§éåŒæœŸé–¢æ•°ã‚’å®Ÿè¡Œã™ã‚‹
    asyncio.run(run_chat(prompt))

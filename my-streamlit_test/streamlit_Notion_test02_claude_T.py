# Notion å¯¾è©±å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€€test2ã®Claudeç‰ˆ & ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ç‰ˆ

import os
import json
import threading

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

import streamlit as st
import asyncio

from autogen_core import CancellationToken
from autogen_core.tools import FunctionTool

from autogen_agentchat.agents import AssistantAgent
# from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_ext.models.anthropic import AnthropicChatCompletionClient
from autogen_agentchat.messages import TextMessage
from autogen_agentchat.agents import AssistantAgent


class McpNotionClient:
    def __init__(self, notion_api_key: str):
        self.notion_api_key = notion_api_key
        self._thread = None
        self._loop = None
        self._ready = threading.Event()
        self._shutdown = None
        self._session = None
        self.tools = []

        self.server_params = StdioServerParameters(
            command="npx",
            args=["-y", "@notionhq/notion-mcp-server"],
            env={**os.environ, 
                 "NOTION_API_KEY": self.notion_api_key
                },
        )

    def start(self):
        self._thread = threading.Thread(target=self._thread_main, daemon=True)
        self._thread.start()
        self._ready.wait(timeout=60)
        if not self._ready.is_set():
            raise RuntimeError("MCP Notion client failed to become ready in time.")

    def close(self):
        if not self._loop:
            return
        asyncio.run_coroutine_threadsafe(self._async_shutdown(), self._loop).result(timeout=30)
        self._loop.call_soon_threadsafe(self._loop.stop)
        if self._thread:
            self._thread.join(timeout=30)

    def call_tool(self, tool_name: str, arguments: dict):
        if not self._ready.is_set():
            raise RuntimeError("MCP Notion client is not ready yet.")
        coro = self._session.call_tool(name=tool_name, arguments=arguments)
        fut = asyncio.run_coroutine_threadsafe(coro, self._loop)
        return fut.result(timeout=60)

    def _thread_main(self):
        self._loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self._loop)
        self._loop.create_task(self._runner())
        self._loop.run_forever()

    async def _runner(self):
        self._shutdown = asyncio.Event()
        async with stdio_client(self.server_params) as (read, write):
            async with ClientSession(read, write) as session:
                await session.initialize()
                self._session = session
                resp = await session.list_tools()
                self.tools = resp.tools
                self._ready.set()
                await self._shutdown.wait()

    async def _async_shutdown(self):
        if self._shutdown:
            self._shutdown.set()


# ãƒ„ãƒ¼ãƒ«ä¸€è¦§ã¯ â€œåå‰ã¨çŸ­ã„èª¬æ˜ã ã‘ã«ã—ã¦ã€schema ã¯å¿…è¦æ™‚ã«ã ã‘å‚ç…§ã™ã‚‹æ–¹å¼ã«ã—ã¾ã™ã€‚
def format_tools_for_prompt_min(mcp_tools) -> str:
    return "\n".join([f"- {t.name}: {t.description}" for t in mcp_tools])

st.set_page_config(page_title="AutoGen x Streamlit App", layout="centered")
st.title("ğŸ¤– AutoGen å¯¾è©±å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")

# --- 1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰ ---
@st.cache_resource
def get_mcp_client():
    notion_token = st.secrets["NOTION_TOKEN"] # Streamlitã§ã¯Secretsç®¡ç†ã‚’æ¨å¥¨
    client = McpNotionClient(notion_api_key=notion_token)
    client.start()  # æ¥ç¶šé–‹å§‹
    return client

# --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾è±¡2: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãƒ„ãƒ¼ãƒ«ã®æ§‹ç¯‰ ---
@st.cache_resource
def get_assistant():
    mcp_client = get_mcp_client() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
    
    # ãƒ„ãƒ¼ãƒ«ã‚«ã‚¿ãƒ­ã‚°ã®ä½œæˆ
#    tools_catalog = format_tools_for_prompt(mcp_client.tools)
    tools_catalog = format_tools_for_prompt_min(mcp_client.tools)

    system_message = (
    "You are a Notion assistant equipped with MCP tools.\n"
    "Use the tool mcp_call_tool.\n"
    "If you need a tool's arguments schema, ask the user for missing info or call get_tool_schema.\n"
    f"\n## Tool List:\n{tools_catalog}"
    )

# Notionã® tool result ã‚’ã€Œãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã™å‰ã«åœ§ç¸®ã€ã™ã‚‹
    def compact_notion_result(tool_name: str, raw):
        # raw ãŒ dict ã ã¨ä»®å®šï¼ˆå®Ÿéš›ã®å‹ã«å¿œã˜ã¦èª¿æ•´ï¼‰
        if isinstance(raw, dict):
            # ä¾‹: ãƒšãƒ¼ã‚¸ä½œæˆçµæœãªã‚‰æœ€ä½é™ã ã‘è¿”ã™
            if "page" in tool_name.lower() or "post-page" in tool_name.lower() or "create" in tool_name.lower():
                return {
                    "id": raw.get("id"),
                    "url": raw.get("url"),
                    "created_time": raw.get("created_time"),
                }
            # search ãªã‚‰å€™è£œã ã‘
            if "search" in tool_name.lower():
                results = raw.get("results", [])
                slim = []
                for r in results[:5]:
                    slim.append({
                        "id": r.get("id"),
                        "object": r.get("object"),
                        "url": r.get("url"),
                    })
                return {"results": slim, "has_more": raw.get("has_more")}
        return raw  # æœ€å¾Œã®ä¿é™ºï¼ˆæœ¬å½“ã¯ã“ã“ã‚‚çµã‚ŠãŸã„ï¼‰

    # ãƒ„ãƒ¼ãƒ«é–¢æ•°å®šç¾©
    def mcp_call_tool(tool_name: str, arguments: dict) -> dict:
    #    result = mcp_client.call_tool(tool_name, arguments)
    #    # JSONå¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯...
    #    return result
        raw = mcp_client.call_tool(tool_name, arguments)
        return compact_notion_result(tool_name, raw)

    mcp_tool = FunctionTool(
        mcp_call_tool,
        name="mcp_call_tool",
        description="Notionã‚’æ“ä½œã™ã‚‹ãŸã‚ã«ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚'tool_name'ã«ã¯å®Ÿè¡Œã—ãŸã„APIåã‚’ã€'arguments'ã«ã¯ãã®APIã«å¿…è¦ãªå¼•æ•°ã‚’è¾æ›¸å½¢å¼ã§æ¸¡ã—ã¦ãã ã•ã„ã€‚ä¾‹: mcp_call_tool(tool_name='API-post-page', arguments={'parent': {...}, 'properties': {...}})",
    )

    # schema ã‚’å¿…è¦æ™‚ã ã‘è¿”ã™è»½ã„ãƒ„ãƒ¼ãƒ«ã‚’è¿½åŠ 
    tool_map = {t.name: t for t in mcp_client.tools}

    def get_tool_schema(tool_name: str) -> dict:
        t = tool_map.get(tool_name)
        if not t:
            return {"error": "unknown tool"}
        return {"name": t.name, "description": t.description, "inputSchema": t.inputSchema}

    schema_tool = FunctionTool(get_tool_schema, name="get_tool_schema",
        description="Return schema for a specific MCP tool.")

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    def get_model_client():
        # st.secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¦æ¸¡ã™
        api_key = st.secrets["ANTHROPIC_API_KEY"]
    
        return AnthropicChatCompletionClient(
        #    model="claude-sonnet-4-20250514",
            model="claude-sonnet-4-5-20250929",
        #    model="claude-haiku-4-5-20251001",
            api_key=api_key, # æ˜ç¤ºçš„ã«æŒ‡å®š
            temperature=0.7,
        )
    if "agent" not in st.session_state:
        client = get_model_client()
#        client._model = "claude-haiku-4-5-20251001"
        st.session_state.agent = AssistantAgent(
            name="assistant",
            model_client=client, # ã“ã“ã«Claudeç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æ¸¡ã™
            system_message=system_message,
        #    tools=[mcp_tool],
            tools=[mcp_tool, schema_tool]
        )
        return st.session_state.agent
    
    return assistant

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
# --- 1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰ ---
assistant = get_assistant()

# --- 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼ˆä¼šè©±å±¥æ­´ã®ä¿å­˜ç”¨ï¼‰ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 3. ä¿å­˜ã•ã‚ŒãŸå±¥æ­´ã®è¡¨ç¤º ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- 4. ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆéåŒæœŸé–¢æ•°ã¨ã—ã¦å®šç¾©ï¼‰ ---
async def run_chat(prompt):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ç”»é¢ã«è¡¨ç¤º & å±¥æ­´ã«è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”é ˜åŸŸã‚’ä½œæˆ
    with st.chat_message("assistant"):
        container = st.empty()  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºç”¨ã®ç©ºæ 
        full_response = ""
        
        # run_stream ã‚’ä½¿ç”¨ã—ã¦é€æ¬¡å–å¾—
        # â€» å®Ÿéš›ã®å®Ÿè£…ã§ã¯ TaskResult ãŒæµã‚Œã¦ãã‚‹ãŸã‚ã€ãã‚Œã‚’å–ã‚Šå‡ºã™
        async for chunk in assistant.run_stream(task=prompt):
            # 1. é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå›ç­”ã®å‡¦ç†
            if isinstance(chunk, TextMessage) and chunk.source == assistant.name:
                full_response += chunk.content
                container.markdown(full_response + "â–Œ") # ã‚«ãƒ¼ã‚½ãƒ«é¢¨ã®æ¼”å‡º
            
            # 2. ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã®å‡¦ç†ã‚’è¿½åŠ 
            elif hasattr(chunk, 'is_error') and chunk.is_error:
                error_msg = f"\n\nâš ï¸ **ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼:** {chunk.content}"
                full_response += error_msg
                container.markdown(full_response)
        
        # æœ€çµ‚çµæœã®è¡¨ç¤ºï¼ˆä½•ã‚‚è¿”ã£ã¦ã“ãªã‹ã£ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        if not full_response:
            full_response = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã«å¤±æ•—ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰ã€‚"
        
        container.markdown(full_response) # æœ€çµ‚çµæœã‚’ç¢ºå®šè¡¨ç¤º
        st.session_state.messages.append({"role": "assistant", "content": full_response})

# --- 5. å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  ---
if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # Streamlitã®åŒæœŸå‡¦ç†ã®ä¸­ã§éåŒæœŸé–¢æ•°ã‚’å®Ÿè¡Œã™ã‚‹
    asyncio.run(run_chat(prompt))

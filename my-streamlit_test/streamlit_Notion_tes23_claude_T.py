# Notion å¯¾è©±å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›å¯¾å¿œ & ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ç‰ˆ

import os
import json
import threading

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

import streamlit as st
import asyncio

from autogen_core import CancellationToken
from autogen_core.tools import FunctionTool

from autogen_agentchat.agents import AssistantAgent
# from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_ext.models.anthropic import AnthropicChatCompletionClient
from autogen_agentchat.messages import TextMessage
from autogen_agentchat.agents import AssistantAgent


class McpNotionClient:
    def __init__(self, notion_api_key: str):
        self.notion_api_key = notion_api_key
        self._thread = None
        self._loop = None
        self._ready = threading.Event()
        self._shutdown = None
        self._session = None
        self.tools = []

        self.server_params = StdioServerParameters(
            command="npx",
            args=["-y", "@notionhq/notion-mcp-server"],
            env={**os.environ, 
                 "NOTION_API_KEY": self.notion_api_key
                },
        )

    def start(self):
        self._thread = threading.Thread(target=self._thread_main, daemon=True)
        self._thread.start()
        self._ready.wait(timeout=60)
        if not self._ready.is_set():
            raise RuntimeError("MCP Notion client failed to become ready in time.")

    def close(self):
        if not self._loop:
            return
        asyncio.run_coroutine_threadsafe(self._async_shutdown(), self._loop).result(timeout=30)
        self._loop.call_soon_threadsafe(self._loop.stop)
        if self._thread:
            self._thread.join(timeout=30)

    def call_tool(self, tool_name: str, arguments: dict):
        if not self._ready.is_set():
            raise RuntimeError("MCP Notion client is not ready yet.")
        coro = self._session.call_tool(name=tool_name, arguments=arguments)
        fut = asyncio.run_coroutine_threadsafe(coro, self._loop)
        return fut.result(timeout=60)

    def _thread_main(self):
        self._loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self._loop)
        self._loop.create_task(self._runner())
        self._loop.run_forever()

    async def _runner(self):
        self._shutdown = asyncio.Event()
        async with stdio_client(self.server_params) as (read, write):
            async with ClientSession(read, write) as session:
                await session.initialize()
                self._session = session
                resp = await session.list_tools()
                self.tools = resp.tools
                self._ready.set()
                await self._shutdown.wait()

    async def _async_shutdown(self):
        if self._shutdown:
            self._shutdown.set()


#def format_tools_for_prompt(mcp_tools) -> str:
#    lines = []
#    for t in mcp_tools:
#        lines.append(
#            f"- name: {t.name}\n"
#            f"  description: {t.description}\n"
#            f"  inputSchema: {json.dumps(t.inputSchema, ensure_ascii=False)}\n"
#        )
#    return "\n".join(lines)

# ãƒ„ãƒ¼ãƒ«ä¸€è¦§ã¯ â€œåå‰ã¨çŸ­ã„èª¬æ˜ã ã‘ã«ã—ã¦ã€schema ã¯å¿…è¦æ™‚ã«ã ã‘å‚ç…§ã™ã‚‹æ–¹å¼ã«ã—ã¾ã™ã€‚
def format_tools_for_prompt_min(mcp_tools) -> str:
    return "\n".join([f"- {t.name}: {t.description}" for t in mcp_tools])

st.set_page_config(page_title="AutoGen x Streamlit App", layout="centered")
st.title("ğŸ¤– AutoGen å¯¾è©±å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")

# --- 1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰ ---
@st.cache_resource
def get_mcp_client():
    notion_token = st.secrets["NOTION_TOKEN"] # Streamlitã§ã¯Secretsç®¡ç†ã‚’æ¨å¥¨
    client = McpNotionClient(notion_api_key=notion_token)
    client.start()  # æ¥ç¶šé–‹å§‹
    return client

# --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾è±¡2: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãƒ„ãƒ¼ãƒ«ã®æ§‹ç¯‰ ---
@st.cache_resource
def get_assistant():
    mcp_client = get_mcp_client() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
    
    # ãƒ„ãƒ¼ãƒ«ã‚«ã‚¿ãƒ­ã‚°ã®ä½œæˆ
#    tools_catalog = format_tools_for_prompt(mcp_client.tools)
    tools_catalog = format_tools_for_prompt_min(mcp_client.tools)

    system_message = (
    "You are a Notion assistant equipped with MCP tools.\n"
    "Use the tool mcp_call_tool.\n"
    "If you need a tool's arguments schema, ask the user for missing info or call get_tool_schema.\n"
    f"\n## Tool List:\n{tools_catalog}"
    )

# Notionã® tool result ã‚’ã€Œãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã™å‰ã«åœ§ç¸®ã€ã™ã‚‹
    def compact_notion_result(tool_name: str, raw):
        # raw ãŒ dict ã ã¨ä»®å®šï¼ˆå®Ÿéš›ã®å‹ã«å¿œã˜ã¦èª¿æ•´ï¼‰
        if isinstance(raw, dict):
            # ä¾‹: ãƒšãƒ¼ã‚¸ä½œæˆçµæœãªã‚‰æœ€ä½é™ã ã‘è¿”ã™
            if "page" in tool_name.lower() or "post-page" in tool_name.lower() or "create" in tool_name.lower():
                return {
                    "id": raw.get("id"),
                    "url": raw.get("url"),
                    "created_time": raw.get("created_time"),
                }
            # search ãªã‚‰å€™è£œã ã‘
            if "search" in tool_name.lower():
                results = raw.get("results", [])
                slim = []
                for r in results[:5]:
                    slim.append({
                        "id": r.get("id"),
                        "object": r.get("object"),
                        "url": r.get("url"),
                    })
                return {"results": slim, "has_more": raw.get("has_more")}
        return raw  # æœ€å¾Œã®ä¿é™ºï¼ˆæœ¬å½“ã¯ã“ã“ã‚‚çµã‚ŠãŸã„ï¼‰

    # ãƒ„ãƒ¼ãƒ«é–¢æ•°å®šç¾©
    def mcp_call_tool(tool_name: str, arguments: dict) -> dict:
    #    result = mcp_client.call_tool(tool_name, arguments)
    #    # JSONå¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯...
    #    return result
        raw = mcp_client.call_tool(tool_name, arguments)
        return compact_notion_result(tool_name, raw)

    mcp_tool = FunctionTool(
        mcp_call_tool,
        name="mcp_call_tool",
        description="Notionã‚’æ“ä½œã™ã‚‹ãŸã‚ã«ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚'tool_name'ã«ã¯å®Ÿè¡Œã—ãŸã„APIåã‚’ã€'arguments'ã«ã¯ãã®APIã«å¿…è¦ãªå¼•æ•°ã‚’è¾æ›¸å½¢å¼ã§æ¸¡ã—ã¦ãã ã•ã„ã€‚ä¾‹: mcp_call_tool(tool_name='API-post-page', arguments={'parent': {...}, 'properties': {...}})",
    )

    # schema ã‚’å¿…è¦æ™‚ã ã‘è¿”ã™è»½ã„ãƒ„ãƒ¼ãƒ«ã‚’è¿½åŠ 
    tool_map = {t.name: t for t in mcp_client.tools}

    def get_tool_schema(tool_name: str) -> dict:
        t = tool_map.get(tool_name)
        if not t:
            return {"error": "unknown tool"}
        return {"name": t.name, "description": t.description, "inputSchema": t.inputSchema}

    schema_tool = FunctionTool(get_tool_schema, name="get_tool_schema",
        description="Return schema for a specific MCP tool.")

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    def get_model_client():
        # st.secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¦æ¸¡ã™
        api_key = st.secrets["ANTHROPIC_API_KEY"]
    
        return AnthropicChatCompletionClient(
        #    model="claude-sonnet-4-20250514",
            model="claude-sonnet-4-5-20250929",
        #    model="claude-haiku-4-5-20251001",
        #    model="claude-4-5-haiku",
        #    model="claude-sonnet-4-haiku",
            api_key=api_key, # æ˜ç¤ºçš„ã«æŒ‡å®š
            temperature=0.7,
        )
    if "agent" not in st.session_state:
        client = get_model_client()
#        client._model = "claude-haiku-4-5-20251001"
        st.session_state.agent = AssistantAgent(
            name="assistant",
            model_client=client, # ã“ã“ã«Claudeç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æ¸¡ã™
            system_message=system_message,
        #    tools=[mcp_tool],
            tools=[mcp_tool, schema_tool]
        )
        return st.session_state.agent
    
#    assistant = AssistantAgent(
#        name="assistant",
#        system_message=system_message,
#        llm_config={
#            "config_list": config_list,
#            "temperature": 0.7,
#        },
#        # model_client=model_client,
#        tools=[mcp_tool],
#    )
    return assistant

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
# --- 1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰ ---
assistant = get_assistant()

# --- 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼ˆä¼šè©±å±¥æ­´ã®ä¿å­˜ç”¨ï¼‰ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 3. ä¿å­˜ã•ã‚ŒãŸå±¥æ­´ã®è¡¨ç¤º ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- 4. ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆéåŒæœŸé–¢æ•°ã¨ã—ã¦å®šç¾©ï¼‰ ---
async def run_chat(prompt):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        container = st.empty()
        full_response = ""
        last_result = None # æœ€çµ‚çµæœã‚’ä¿æŒã™ã‚‹å¤‰æ•°
        
        async for chunk in assistant.run_stream(task=prompt):
            # å‹ã«ã“ã ã‚ã‚‰ãšã€ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            content = getattr(chunk, "content", "")
            
            # content ãŒãƒªã‚¹ãƒˆå½¢å¼ï¼ˆMultiModalï¼‰ã§è¿”ã£ã¦ãã‚‹å ´åˆã‚‚ã‚ã‚‹ãŸã‚æ–‡å­—åˆ—ã«å¤‰æ›
            if isinstance(content, list):
                text_parts = [item for item in content if isinstance(item, str)]
                content = "\n".join(text_parts)
            
            if content and isinstance(content, str):
                # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œæ™‚ã®ãƒ­ã‚°ã§ã¯ãªãã€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦ã®ç™ºè¨€ã‚’å„ªå…ˆ
                if getattr(chunk, "source", "") == assistant.name:
                    full_response += content
                    container.markdown(full_response + "â–Œ")
            
            # æœ€çµ‚çš„ãª TaskResult ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¦ãŠã
            last_result = chunk 

        # --- ã“ã“ã‹ã‚‰ãŒé‡è¦ï¼šãƒ‡ãƒ¼ã‚¿ãŒè¡¨ç¤ºã•ã‚Œãªã„å•é¡Œã®å¯¾ç­– ---
        if not full_response and last_result:
            # ã‚¹ãƒˆãƒªãƒ¼ãƒ ä¸­ã«æ‹¾ãˆãªã‹ã£ãŸå ´åˆã€ã“ã‚Œã¾ã§ã®å…¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã€Œæœ€å¾Œã®å›ç­”ã€ã‚’æ¢ã™
            messages = getattr(last_result, "messages", [])
            for msg in reversed(messages):
                if msg.source == assistant.name and msg.content:
                    if isinstance(msg.content, str):
                        full_response = msg.content
                        break
                    # MultiModalMessageã®å ´åˆã®æŠ½å‡º
                    #ã‚°ãƒªãƒ¼ãƒ³
                    elif isinstance(msg.content, list):
                        full_response = "\n".join([c for c in msg.content if isinstance(c, str)])
                        break
        
        if not full_response:
            full_response = "ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸãŒã€è¡¨ç¤ºã§ãã‚‹å½¢å¼ã®å›ç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        container.markdown(full_response)
        st.session_state.messages.append({"role": "assistant", "content": full_response})


# --- 5. å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  ---
if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # Streamlitã®åŒæœŸå‡¦ç†ã®ä¸­ã§éåŒæœŸé–¢æ•°ã‚’å®Ÿè¡Œã™ã‚‹
    asyncio.run(run_chat(prompt))
